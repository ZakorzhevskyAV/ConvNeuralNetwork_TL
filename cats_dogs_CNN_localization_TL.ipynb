{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cats_dogs_CNN_localization_TL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_vd8QiI4WcZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "import pathlib\n",
        "from PIL import Image, ImageDraw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJlhxSXSuYwI"
      },
      "source": [
        "from tensorflow.keras.layers import InputLayer, Input\n",
        "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.applications import xception\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
        "from tensorflow.keras import backend as K\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX18Mz4X4bzp"
      },
      "source": [
        "# в данном решении необходимые файлы хранятся на Google Drive\n",
        "# получить доступ к Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqruXrA14djb"
      },
      "source": [
        "# сохранить пути до датасетов\n",
        "train_dataset_dir = pathlib.Path(\n",
        "    \"/content/drive/My Drive/cats_dogs_dataset/train\")\n",
        "valid_dataset_dir = pathlib.Path(\n",
        "    \"/content/drive/My Drive/cats_dogs_dataset/valid\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3iCSzrk7kv9"
      },
      "source": [
        "# сохранить и отсортировать пути до каждой картинки и каждого текстового файла\n",
        "train_images_paths = list(train_dataset_dir.glob('*.jpg'))\n",
        "train_labels_paths = list(train_dataset_dir.glob('*.txt'))\n",
        "valid_images_paths = list(valid_dataset_dir.glob('*.jpg'))\n",
        "valid_labels_paths = list(valid_dataset_dir.glob('*.txt'))\n",
        "\n",
        "train_images_paths.sort()\n",
        "train_labels_paths.sort()\n",
        "valid_images_paths.sort()\n",
        "valid_labels_paths.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfdgPVn974cp"
      },
      "source": [
        "# сохранить значения длины каждого списка из путей\n",
        "t_img_len = len(train_images_paths)\n",
        "t_txt_len = len(train_labels_paths)\n",
        "v_img_len = len(valid_images_paths)\n",
        "v_txt_len = len(valid_labels_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq7V0UWh7pxT"
      },
      "source": [
        "# создание массива для хранения тренировочных категорических векторов классов\n",
        "train_class_array = np.zeros([t_txt_len, 2], dtype=('float64'))\n",
        "\n",
        "# создание массива для хранения тренировочных координат bounding box'а\n",
        "train_coord_array = np.empty([t_txt_len, 4], dtype=('float64'))\n",
        "\n",
        "# заполнение массивов для хранения тренировочных координат и классов\n",
        "for i in range(t_txt_len):\n",
        "\n",
        "# создание категорического вектора классов\n",
        "# первая позиция - кошка, вторая - собака\n",
        "  train_class_array[i][np.loadtxt(train_labels_paths[i], dtype=int)[0]-1] = 1\n",
        "\n",
        "# заполнение массива для хранения координат bounding box'а\n",
        "  train_coord_array[i] = np.loadtxt(train_labels_paths[i])[1:]\n",
        "\n",
        "# создание массива для хранения валидационных категорических векторов классов\n",
        "valid_class_array = np.zeros([v_txt_len, 2], dtype=('float64'))\n",
        "\n",
        "# создание массива для хранения валидационных координат bounding box'а\n",
        "valid_coord_array = np.empty([v_txt_len, 4], dtype=('float64'))\n",
        "\n",
        "# заполнение массивов для хранения валидационных координат и классов\n",
        "for i in range(v_txt_len):\n",
        "\n",
        "# создание категорического вектора классов\n",
        "# первая позиция - кошка, вторая - собака\n",
        "  valid_class_array[i][np.loadtxt(valid_labels_paths[i], dtype=int)[0]-1] = 1\n",
        "\n",
        "# заполнение массива для хранения координат bounding box'а\n",
        "  valid_coord_array[i] = np.loadtxt(valid_labels_paths[i])[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWL2br4N7Gn8"
      },
      "source": [
        "# создание массива для хранения тренировочных изображений 256х256\n",
        "train_img_arr = np.zeros((t_img_len, 256, 256, 3), dtype=('float64'))\n",
        "\n",
        "# создание массива для множителей изменения размера тренировочных изображений\n",
        "# для возможности вывода bounding box'а на исходных изображениях\n",
        "# 256 * множитель = изначальный размер изображения\n",
        "# первая позиция - x, вторая - y\n",
        "t_resize_factor_array = np.zeros((t_img_len, 2), dtype=('float64'))\n",
        "\n",
        "# заполнение массива для хранения тренировочных изображений 256х256\n",
        "for i in range(t_img_len):\n",
        "\n",
        "# запись тренировочного изображения в переменную\n",
        "  jpg_file = load_img(train_images_paths[i])\n",
        "\n",
        "# расчет множителей изменения размера тренировочных изображений\n",
        "  t_resize_factor_array[i][0] = jpg_file.size[0]/256 # x\n",
        "  t_resize_factor_array[i][1] = jpg_file.size[1]/256 # y\n",
        "\n",
        "# превращение тренировочных координат в относительные, т.е. в промежутке [0,1]\n",
        "  train_coord_array[i][0] = (\n",
        "      train_coord_array[i][0]/jpg_file.size[0]\n",
        "  )\n",
        "  train_coord_array[i][1] = (\n",
        "      train_coord_array[i][1]/jpg_file.size[1]\n",
        "  )\n",
        "  train_coord_array[i][2] = (\n",
        "      train_coord_array[i][2]/jpg_file.size[0]\n",
        "  )\n",
        "  train_coord_array[i][3] = (\n",
        "      train_coord_array[i][3]/jpg_file.size[1]\n",
        "  )\n",
        "\n",
        "# изменение размера картинки и превращение её в массив numpy\n",
        "  jpg_file_arr = img_to_array(jpg_file.copy().resize((256, 256)))\n",
        "\n",
        "# заполнение массива для хранения тренировочных изображений 256х256\n",
        "  train_img_arr[i] = xception.preprocess_input(jpg_file_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WejQmlQs7AT4"
      },
      "source": [
        "# создание массива для хранения валидационных изображений 256х256\n",
        "valid_img_arr = np.zeros((v_img_len, 256, 256, 3), dtype=('float64'))\n",
        "\n",
        "# создание массива для множителей изменения размера валидационных изображений\n",
        "# для возможности вывода bounding box'а на исходных изображениях\n",
        "# 256 * множитель = изначальный размер изображения\n",
        "# первая позиция - x, вторая - y\n",
        "v_res_to_orig_multipliers_array = np.zeros((v_img_len, 2), dtype=('float64'))\n",
        "\n",
        "# заполнение массива для хранения валидационных изображений 256х256\n",
        "for i in range(v_img_len):\n",
        "\n",
        "# запись валидационных изображения в переменную\n",
        "  jpg_file = load_img(valid_images_paths[i])\n",
        "\n",
        "# расчет множителей изменения размера валидационных изображений\n",
        "  v_res_to_orig_multipliers_array[i][0] = jpg_file.size[0]/256\n",
        "  v_res_to_orig_multipliers_array[i][1] = jpg_file.size[1]/256\n",
        "\n",
        "# превращение валидационных координат в относительные, т.е. в промежутке [0,1]\n",
        "  valid_coord_array[i][0] = (\n",
        "      valid_coord_array[i][0]/jpg_file.size[0]\n",
        "  )\n",
        "  valid_coord_array[i][1] = (\n",
        "      valid_coord_array[i][1]/jpg_file.size[1]\n",
        "  )\n",
        "  valid_coord_array[i][2] = (\n",
        "      valid_coord_array[i][2]/jpg_file.size[0]\n",
        "  )\n",
        "  valid_coord_array[i][3] = (\n",
        "      valid_coord_array[i][3]/jpg_file.size[1]\n",
        "  )\n",
        "\n",
        "# изменение размера картинки и превращение её в массив numpy\n",
        "  jpg_file_arr = img_to_array(jpg_file.copy().resize((256, 256)))\n",
        "\n",
        "# заполнение массива для хранения валидационных изображений 256х256\n",
        "  valid_img_arr[i] = xception.preprocess_input(jpg_file_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L8nMLqDIzMX"
      },
      "source": [
        "# загрузка и настройка модели Xception\n",
        "# обучение и полносвязный слой для загруженной модели должны быть отключены\n",
        "TL_model = Xception(\n",
        "    weights = 'imagenet',\n",
        "    input_shape = (256,256,3),\n",
        "    include_top = False\n",
        ")\n",
        "TL_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcPaAdhlXvwj"
      },
      "source": [
        "# создание модели свёрточной нейронной сети\n",
        "input_ = Input(shape=(256, 256, 3), name='images')\n",
        "x = TL_model(input_, training = False)\n",
        "\n",
        "x = Conv2D(kernel_size=3, strides=1, filters=128, padding='same',\n",
        "                 activation='relu', name='layer_conv1')(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "# полносвязные слои для определения класса\n",
        "x1 = Dense(128, activation = 'relu')(x)\n",
        "x1 = Dropout(0.5)(x1)\n",
        "x1 = Dense(64, activation = 'relu')(x1)\n",
        "\n",
        "# полносвязные слои для определения координат\n",
        "x2 = Dense(128, activation = 'relu')(x)\n",
        "x2 = Dropout(0.5)(x2)\n",
        "x2 = Dense(64, activation = 'relu')(x2)\n",
        "\n",
        "# вывод класса\n",
        "class_output = Dense(2, activation='softmax', name = 'class_output')(x1)\n",
        "\n",
        "# вывод координат\n",
        "bbox_output = Dense(4, activation='sigmoid', name = 'bbox_output')(x2)\n",
        "\n",
        "model = tf.keras.models.Model(input_, [class_output, bbox_output])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knLlDrWEw5bi"
      },
      "source": [
        "# метрика IoU\n",
        "def iou_metric(y_true, y_pred):\n",
        "    \n",
        "    # площадь groundtruth box'а\n",
        "    gt_area = K.abs(K.transpose(y_true)[2] - K.transpose(y_true)[0]\n",
        "                ) * K.abs(K.transpose(y_true)[3] - K.transpose(y_true)[1])\n",
        "    \n",
        "    # площадь предсказанного box'а\n",
        "    pred_area = K.abs(K.transpose(y_pred)[2] - K.transpose(y_pred)[0]\n",
        "                ) * K.abs(K.transpose(y_pred)[3] - K.transpose(y_pred)[1])\n",
        "\n",
        "    # координаты области пересечения\n",
        "    xmin = K.maximum(K.transpose(y_true)[0], K.transpose(y_pred)[0])\n",
        "    ymin = K.maximum(K.transpose(y_true)[1], K.transpose(y_pred)[1])\n",
        "    xmax = K.maximum(K.transpose(y_true)[2], K.transpose(y_pred)[2])\n",
        "    ymax = K.maximum(K.transpose(y_true)[3], K.transpose(y_pred)[3])\n",
        "\n",
        "    # площадь пересечения\n",
        "    intersection = (xmax - xmin) * (ymax - ymin)\n",
        "\n",
        "    # площадь объединения\n",
        "    union = gt_area + pred_area - intersection\n",
        "    \n",
        "    # вычисление IoU\n",
        "    iou = intersection / union\n",
        "\n",
        "    # привязать значения IoU к диапазону [0,1]\n",
        "    iou = K.clip(iou, 0.0 + K.epsilon(), 1.0 - K.epsilon())\n",
        "\n",
        "    return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O10wutqwYjvJ"
      },
      "source": [
        "model.compile(\n",
        "    loss={\n",
        "        'class_output': 'categorical_crossentropy',\n",
        "        'bbox_output': 'mse'\n",
        "    },\n",
        "    optimizer=tf.keras.optimizers.RMSprop(\n",
        "        ),\n",
        "    metrics={\n",
        "        'class_output': 'accuracy',\n",
        "        'bbox_output': [iou_metric]\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHBBcmVuT94P"
      },
      "source": [
        "model.fit(\n",
        "    x = train_img_arr,\n",
        "    y = {\n",
        "        'class_output': train_class_array, \n",
        "        'bbox_output': train_coord_array\n",
        "        },\n",
        "    epochs=20,\n",
        "    verbose = 1,\n",
        "    validation_data = ({\n",
        "        'images': valid_img_arr\n",
        "    },\n",
        "    {\n",
        "        'class_output': valid_class_array,\n",
        "        'bbox_output': valid_coord_array\n",
        "    }),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKD0qy5otuN8"
      },
      "source": [
        "# вывод истинного и предсказанного bounding box'а на изображение\n",
        "def plot_bounding_box(image, gt_coords, pred_coords = []):\n",
        "  draw = ImageDraw.Draw(image)\n",
        "\n",
        "# вывод истинного bounding box'а на изображение\n",
        "  if len(gt_coords) == 4:\n",
        "    xmin, ymin, xmax, ymax = gt_coords\n",
        "    draw.rectangle((xmin, ymin, xmax, ymax), outline='green', width=3)\n",
        "\n",
        "# вывод предсказанного bounding box'а на изображение\n",
        "  if len(pred_coords) == 4:\n",
        "    xmin, ymin, xmax, ymax = pred_coords\n",
        "    draw.rectangle((xmin, ymin, xmax, ymax), outline='red', width=3)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q__GKW29Bgs-"
      },
      "source": [
        "# выбрать номер картинки из массива\n",
        "img_num = 0\n",
        "\n",
        "# извлечь координаты предсказанного bounding box'а\n",
        "pred_bbox = model.predict(valid_img_arr[img_num:img_num+1])[1][0]*256\n",
        "\n",
        "# извлечь координаты истинного bounding box'а\n",
        "gt_bbox = valid_coord_array[img_num]*256\n",
        "\n",
        "# записать выбранную картинку в виде массива numpy\n",
        "bb_img = array_to_img(valid_img_arr[img_num])\n",
        "\n",
        "# нанести на картинку истинный и предсказанный bounding box\n",
        "bb_img = plot_bounding_box(bb_img, gt_bbox, pred_bbox)\n",
        "\n",
        "# вывести картинку с bounding box'ами на экран\n",
        "plt.imshow(bb_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9t3_lgBVvog"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tZglaGrV0pW"
      },
      "source": [
        "# оценка inference time'а одной картинки\n",
        "start = time.time()\n",
        "model.predict(valid_img_arr[0:1])\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RmpfCpHWdYT"
      },
      "source": [
        "# оценка inference time'а десяти картинок и одной из них отдельно\n",
        "# часть времени при предсказании затрачивается на сопутствующие вычисления\n",
        "start = time.time()\n",
        "model.predict(valid_img_arr[0:10])\n",
        "end = time.time()\n",
        "print(end - start)\n",
        "print((end - start)/10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbLoWsX3wHbI"
      },
      "source": [
        "# 796s 8s/step \n",
        "#    - loss: 0.0034 - class_output_loss: 3.3889e-05 -     bbox_output_loss: 0.0034 -     class_output_accuracy: 1.0000 -     bbox_output_iou_metric: 0.9373 \n",
        "#- val_loss: 0.0395 - val_class_output_loss: 0.0325 - val_bbox_output_loss: 0.0070 - val_class_output_accuracy: 0.9950 - val_bbox_output_iou_metric: 0.9217"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOMtgNJy3e7r"
      },
      "source": [
        "# 20 эпох, связки по 32 элемента\n",
        "# точность классификации: 99.5%\n",
        "# IoU: 92.17%\n",
        "# inference time для 1 картинки: 0.34979748725891113, ~350 мс\n",
        "# inference time для 10 картинок: 2.3396732807159424, ~2.34 с\n",
        "# inference time для 1 картинки из 10: 0.23396732807159423, ~234 мс\n",
        "# количество элементов в тренировочной выборке: 2985\n",
        "# количество элементов в валидационной выборке: 400"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}